## LeNet-5
 * Conv filters were 5x5 applied at stride 1
 * Subsampling(pooling) layers were 2x2 applied at stride 2

## AlexNet
 * 227x227x3 images (data from ImageNet)
 * after CONV1: 55x55x96 
   (개발당시 사용했던 GPU GTX 580에 메모리가 
   충분하지 않아서 55x55x48 2개로 나누어 사용)
 * ...
 * 13x13x256
 * 13x13x284
 * 6x6x256
 * 4096 -> 4096
 * 1000

 * first use of ReLU
 * used Norm layers
 * heavy data augmentation
 * dropout 0.5
 * batch size 128
 * SGDd Momentum 0.9
 * learning rate 1e-2, reduced by 10 manully when val accuracy plateaus
 * L2 weight decay 5e-4
 * 7 CNN ensemble: 18.2% -> 15.4%

## VGGNet
 * 3 3x3 CONV (stride 1)
   이게 3층이 되면 결국 has same effective receptive field as one 7x7 
   conv layer
 * fewer parameters
   3 x (3^2 x C^2) vs 7^2 x C^2
   => 27 : 49
 * forward에 이미지당 134M
 * conv, fc 두 가지 layer는 weight가 training 가능하다.

## GoogLeNet
 * 22 layers(가중치가 있는 레이어)

 * Efficient "Inception" module
   Network in Network or NiN (local topology)
 * No FC layers
 * 12x less params than AlextNet
   5 million (AlexNet 60 million)

 * dimension reduction

 * ILSVRC'14 classification winner

